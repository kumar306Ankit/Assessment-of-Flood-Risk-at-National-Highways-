{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "160a5fe8-04b5-448d-9c08-0775a10584fd",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1320e126-419c-4bbf-8546-892333043019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: certifi in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (2024.7.4)\n",
      "Requirement already satisfied: pip in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (24.1.2)\n",
      "Requirement already satisfied: pooch in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (1.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from pooch) (4.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from pooch) (24.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from pooch) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from requests>=2.19.0->pooch) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from requests>=2.19.0->pooch) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from requests>=2.19.0->pooch) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from requests>=2.19.0->pooch) (2024.7.4)\n",
      "Looking in indexes: http://pypi.python.org/simple/\n",
      "Requirement already satisfied: pooch in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (1.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from pooch) (4.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from pooch) (24.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from pooch) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from requests>=2.19.0->pooch) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from requests>=2.19.0->pooch) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from requests>=2.19.0->pooch) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from requests>=2.19.0->pooch) (2024.7.4)\n",
      "Requirement already satisfied: matplotlib in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (3.7.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from matplotlib) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.20 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from matplotlib) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from matplotlib) (6.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.19.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: docx2pdf in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (0.1.8)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from docx2pdf) (4.66.4)\n",
      "Requirement already satisfied: seaborn in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from seaborn) (1.24.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from seaborn) (2.0.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from seaborn) (3.7.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (6.4.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.4->seaborn) (3.19.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Requirement already satisfied: folium in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (0.17.0)\n",
      "Requirement already satisfied: branca>=0.6.0 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from folium) (0.7.2)\n",
      "Requirement already satisfied: jinja2>=2.9 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from folium) (3.1.4)\n",
      "Requirement already satisfied: numpy in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from folium) (1.24.4)\n",
      "Requirement already satisfied: requests in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from folium) (2.32.3)\n",
      "Requirement already satisfied: xyzservices in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from folium) (2024.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from jinja2>=2.9->folium) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from requests->folium) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from requests->folium) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from requests->folium) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from requests->folium) (2024.7.4)\n",
      "Requirement already satisfied: openpyxl in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (3.1.4)\n",
      "Requirement already satisfied: et-xmlfile in /home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages (from openpyxl) (1.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user3/miniconda3/envs/ankit_intern/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade certifi\n",
    "!pip install --upgrade pip\n",
    "!pip install --trusted-host pypi.org pooch\n",
    "!pip install --index-url=http://pypi.python.org/simple/ --trusted-host pypi.python.org pooch\n",
    "!pip install --upgrade matplotlib\n",
    "!pip install docx2pdf\n",
    "!pip install seaborn\n",
    "!pip install folium\n",
    "!pip install openpyxl\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.backends.backend_agg as agg\n",
    "from io import BytesIO\n",
    "from scipy import stats\n",
    "from scipy.stats import genextreme as gev\n",
    "import pooch\n",
    "import tempfile\n",
    "import docx2pdf\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c89450f-fdc9-4b3f-965d-33277481ffd7",
   "metadata": {},
   "source": [
    "# Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7dda82c-5bb6-4829-a0c3-dd9bb13e278a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import genextreme as gev\n",
    "from scipy.optimize import minimize\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "class AnnualMaxPrecipitationAnalyzer:\n",
    "    def __init__(self, folder_path, excel_file_path, intersection_point_path, GMT_File_Path,data_start_year = 1951 ,start_year=1951, end_year=2022,return_periods=[25, 50, 100]):\n",
    "        # initialize inputs\n",
    "        self.folder_path = folder_path\n",
    "        self.excel_file_path = excel_file_path\n",
    "        self.intersection_point_path = intersection_point_path\n",
    "        self.GMT_File_Path = GMT_File_Path\n",
    "        self.start_year = start_year\n",
    "        self.end_year = end_year\n",
    "        self.data_start_year = data_start_year\n",
    "        self.return_periods = return_periods\n",
    "        #read file\n",
    "        self.df = pd.read_excel(self.excel_file_path)\n",
    "        self.intersection_df = pd.read_excel(self.intersection_point_path)\n",
    "        self.annual_precipitation_latitude_longitude = {}\n",
    "        self.colors = sns.color_palette(\"husl\", len(os.listdir(folder_path)))\n",
    "        self.years = list(range(self.start_year, self.end_year + 1))\n",
    "        # initialize variables\n",
    "        self.risk_factors = {}\n",
    "        self.shape = None\n",
    "        self.loc = None\n",
    "        self.scale = None\n",
    "        self.resultsNon_Stationary_Stationary_Analysis_location_vary = []\n",
    "        self.resultsNon_Stationary_Stationary_Analysis_splitwise = []\n",
    "        self.daily_precipitation = []\n",
    "\n",
    "\n",
    "\n",
    "    def process_files(self, duration=1):\n",
    "        self.years_range = pd.date_range(start=f'{self.start_year}-01-01', end=f'{self.end_year}-12-31', freq='Y').year\n",
    "        for i, filename in enumerate(os.listdir(self.folder_path)):\n",
    "            if filename.startswith(\"data_\"):\n",
    "                lat_lon = filename.replace(\"data_\", \"\").split(\"_\")\n",
    "                latitude, longitude = float(lat_lon[0]), float(lat_lon[1])\n",
    "                if ((self.df['Latitude'] == latitude) & (self.df['Longitude'] == longitude)).any():\n",
    "                    file_path = os.path.join(self.folder_path, filename)\n",
    "                    with open(file_path, 'r') as file:\n",
    "                        lines = file.readlines()\n",
    "                    data_list = [line.strip().split() for line in lines]\n",
    "                    columns = ['Precipitation(mm)', 'Tmax(Degree Celcius)', 'Tmin(Degree Celcius)', 'Wind(m/s)']\n",
    "                    df_file = pd.DataFrame(data_list, columns=columns)\n",
    "                    df_file['Date'] = pd.date_range(start=f'{self.data_start_year}-01-01', periods=len(df_file), freq='D')\n",
    "                    start_date = f'{self.end_year + 1}-01-01'\n",
    "                    df_filtered = df_file[(df_file['Date'] < start_date)].copy()\n",
    "                    df_filtered['Precipitation(mm)'] = pd.to_numeric(df_filtered['Precipitation(mm)'], errors='coerce')\n",
    "                    self.daily_precipitation.append(df_filtered[['Date', 'Precipitation(mm)']])\n",
    "\n",
    "        # Combine daily precipitation data from all files\n",
    "        Daily_Precipitation_All_Points_In_Catchment = pd.concat(self.daily_precipitation)\n",
    "        Daily_Precipitation_Catchment = Daily_Precipitation_All_Points_In_Catchment.groupby('Date')['Precipitation(mm)'].mean().reset_index()\n",
    "\n",
    "        # Calculate annual maximum precipitation for the specified duration\n",
    "        Daily_Precipitation_Catchment['Year'] = Daily_Precipitation_Catchment['Date'].dt.year\n",
    "        Annual_Maxima_Precipitation_Catchment = []\n",
    "\n",
    "        for year in self.years_range:\n",
    "            year_data = Daily_Precipitation_Catchment[Daily_Precipitation_Catchment['Year'] == year]\n",
    "            if len(year_data) > 0:\n",
    "                rolling_sum = year_data['Precipitation(mm)'].rolling(window=duration, min_periods=1).sum()\n",
    "                max_precip = rolling_sum.max()\n",
    "                Annual_Maxima_Precipitation_Catchment.append(max_precip if np.isfinite(max_precip) else np.nan)\n",
    "            else:\n",
    "                Annual_Maxima_Precipitation_Catchment.append(np.nan)\n",
    "\n",
    "        # Now Annual_Maxima_Precipitation_Catchment will have the same length as self.years_range\n",
    "        self.Annual_Maxima_Precipitation_Catchment = Annual_Maxima_Precipitation_Catchment\n",
    "#         print(len(self.Annual_Maxima_Precipitation_Catchment))\n",
    "\n",
    "        # Read the GMT file correctly\n",
    "        GMT_File = pd.read_csv(self.GMT_File_Path, delim_whitespace=True, header=None, skiprows=1)\n",
    "        columns = ['Years', 'Historical', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
    "        GMT_File.columns = columns\n",
    "        \n",
    "        # Extract the years and Global Mean Temperature columns\n",
    "        GMT = GMT_File[['Years', 'Historical', 'ssp126', 'ssp245', 'ssp370', 'ssp585']]\n",
    "        GMT[['Historical', 'ssp126', 'ssp245', 'ssp370', 'ssp585']] -= 273.15\n",
    "        \n",
    "        # Filter data to include only years present in self.years\n",
    "        GMT_start_to_end_year = GMT[GMT['Years'].isin(self.years)]\n",
    "        GMT_start_to_end_year = GMT_start_to_end_year.reset_index(drop=True)\n",
    "        \n",
    "        # Create a DataFrame to combine average annual precipitation and global mean temperature\n",
    "        Analyze_Data = pd.DataFrame({\n",
    "            'Years': self.years,\n",
    "            'Average Annual Precipitation': self.Annual_Maxima_Precipitation_Catchment\n",
    "        })\n",
    "        \n",
    "        # Merge the dataframes on 'Years'\n",
    "        self.Analyze_Data = pd.merge(Analyze_Data, GMT_start_to_end_year, on='Years', how='inner')\n",
    "    \n",
    "        # print(self.Analyze_Data)\n",
    "    def Non_Stationary_Stationary_Analysis_Using_Window_Size(self,window_size=1):\n",
    "       \n",
    "        # Perform Stationary GEV Analysis to get initial parameters\n",
    "        shape_SS, loc_SS, scale_SS = gev.fit(self.Annual_Maxima_Precipitation_Catchment)\n",
    "        print(f\"Stationary GEV Parameters: loc={loc_SS}, scale={scale_SS}, shape={shape_SS}\")\n",
    "   \n",
    "        # Calculate return levels using stationary parameters\n",
    "        stationary_return_levels = {}\n",
    "        for rp in self.return_periods:\n",
    "            stationary_return_levels[rp] = gev.ppf(1 - 1/rp, c=shape_SS, loc=loc_SS, scale=scale_SS)\n",
    "   \n",
    "        gev_parameters_list = []  # Initialize a list to collect parameters\n",
    "        return_levels = {rp: [] for rp in self.return_periods}  # Dictionary to store return levels for each return period\n",
    "\n",
    "        for i in range(len(self.Annual_Maxima_Precipitation_Catchment) - window_size + 1):\n",
    "            window_years = self.years_range[i:i + window_size]\n",
    "            window_precip = self.Annual_Maxima_Precipitation_Catchment[i:i + window_size]\n",
    "\n",
    "            # Remove non-finite values from the window_precip\n",
    "            window_precip = [x for x in window_precip if np.isfinite(x)]\n",
    "\n",
    "            if len(window_precip) > 0:  # Only fit if there are finite values\n",
    "                shape, loc, scale = gev.fit(window_precip)\n",
    "                gev_parameters_list.append({'Year': int(window_years[-1]), 'Shape': shape, 'Location': loc, 'Scale': scale})\n",
    "\n",
    "                # Calculate return levels for each return period\n",
    "                for rp in self.return_periods:\n",
    "                    return_level = gev.ppf(1 - 1/rp, c=shape, loc=loc, scale=scale)\n",
    "                    return_levels[rp].append(return_level)\n",
    "                   \n",
    "       \n",
    "        # Convert the list of dictionaries to a DataFrame and append to self.gev_parameters\n",
    "        self.gev_parameters = pd.DataFrame(gev_parameters_list)\n",
    "        mean_location = self.gev_parameters['Location'].mean()\n",
    "        mean_scale = self.gev_parameters['Scale'].mean()\n",
    "        mean_shape = self.gev_parameters['Shape'].mean()\n",
    "       \n",
    "        # Calculate return levels for each return period for last year\n",
    "        non_stationary_return_levels_mean_paramters = {}\n",
    "        for rp in self.return_periods:\n",
    "            non_stationary_return_levels_mean_paramters[rp] = gev.ppf(1 - 1/rp, c=mean_shape, loc=mean_location, scale=mean_scale)\n",
    "\n",
    "        # Check if catchment ID is present in the intersection DataFrame\n",
    "        filename = os.path.splitext(os.path.basename(self.excel_file_path))[0]\n",
    "        self.catchment_id = int(filename)\n",
    "        self.intersection_df['Catchment ID'] = self.intersection_df['Catchment ID'].astype(int)\n",
    "        filtered_df = self.intersection_df[self.intersection_df['Catchment ID'] == self.catchment_id]\n",
    "        if not filtered_df.empty:\n",
    "            self.Latitude = filtered_df['Latitude'].values[0]\n",
    "            self.Longitude = filtered_df['Longitude'].values[0]\n",
    "            self.resultsNon_Stationary_Stationary_Analysis_splitwise.append({\n",
    "            'Catchment ID': self.catchment_id,\n",
    "                'Latitude' : self.Latitude,\n",
    "                'Longitude' : self.Longitude,\n",
    "            'Stationary Location parameter': loc_SS,\n",
    "            'Stationary Shape parameter': shape_SS,\n",
    "            'Stationary Scale parameter': scale_SS,\n",
    "            **{f'Stationary Return value for {rp}-year': stationary_return_levels[rp].item() if isinstance(stationary_return_levels[rp], np.ndarray) else stationary_return_levels[rp] for rp in self.return_periods},\n",
    "            'Location parameter Mean': mean_location,\n",
    "            'Shape parameter Mean': mean_shape,\n",
    "            'Scale parameter Mean': mean_scale,        \n",
    "            **{f'Non-Stationary Return value for {rp}-year': non_stationary_return_levels_mean_paramters[rp].item() if isinstance(non_stationary_return_levels_mean_paramters[rp], np.ndarray) else non_stationary_return_levels_mean_paramters[rp] for rp in self.return_periods},\n",
    "            **{f'Change in Precipitation for return period {rp}-year': (non_stationary_return_levels_mean_paramters[rp] - stationary_return_levels[rp]).item() if isinstance((non_stationary_return_levels_mean_paramters[rp] - stationary_return_levels[rp]), np.ndarray) else non_stationary_return_levels_mean_paramters[rp] - stationary_return_levels[rp] for rp in self.return_periods}  \n",
    "            })\n",
    "        else:\n",
    "            self.Latitude = None\n",
    "            self.Longitude = None\n",
    "            print(f\"No matching catchment ID {self.catchment_id} found in the intersection DataFrame. Skipping.\")\n",
    "\n",
    "        print(self.catchment_id)\n",
    "        plt.figure(figsize=(15, 5))\n",
    "\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.plot(self.gev_parameters['Year'], self.gev_parameters['Location'], marker='o')\n",
    "        plt.title('Location Parameter Over Time')\n",
    "        plt.xlabel('Year')\n",
    "        plt.ylabel('Location Parameter')\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.plot(self.gev_parameters['Year'], self.gev_parameters['Scale'], marker='o')\n",
    "        plt.title('Scale Parameter Over Time')\n",
    "        plt.xlabel('Year')\n",
    "        plt.ylabel('Scale Parameter')\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.plot(self.gev_parameters['Year'], self.gev_parameters['Shape'], marker='o')\n",
    "        plt.title('Shape Parameter Over Time')\n",
    "        plt.xlabel('Year')\n",
    "        plt.ylabel('Shape Parameter')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Plot return levels for each return period\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        for rp in self.return_periods:\n",
    "            plt.plot(self.gev_parameters['Year'], return_levels[rp], marker='o', label=f'{rp}-Year Return Level')\n",
    "\n",
    "        plt.title('Return Levels Over Time')\n",
    "        plt.xlabel('Year')\n",
    "        plt.ylabel('Return Level')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "       \n",
    "       \n",
    "    def Non_Stationary_Stationary_Analysis_location_vary(self,type_model):\n",
    "        Dataset = self.Analyze_Data\n",
    "        years = Dataset['Years'].values\n",
    "        annual_max_precip = Dataset['Average Annual Precipitation'].values\n",
    "        gmt = Dataset[type_model].values\n",
    "        # print(gmt)\n",
    "        gmt_end = Dataset[Dataset['Years']==self.end_year][type_model].values\n",
    "        # Ensure that the data does not contain any NaN values\n",
    "        mask = ~np.isnan(annual_max_precip)\n",
    "        years = years[mask]\n",
    "        annual_max_precip = annual_max_precip[mask]\n",
    "        gmt = gmt[mask]\n",
    "   \n",
    "        # Perform Stationary GEV Analysis to get initial parameters\n",
    "        shape, loc, scale = gev.fit(annual_max_precip)\n",
    "        # print(f\"Stationary GEV Parameters: loc={loc}, scale={scale}, shape={shape}\")\n",
    "   \n",
    "        # Calculate return levels using stationary parameters\n",
    "        stationary_return_levels = {}\n",
    "        for rp in self.return_periods:\n",
    "            stationary_return_levels[rp] = gev.ppf(1 - 1/rp, c=shape, loc=loc, scale=scale)\n",
    "   \n",
    "        # Use stationary parameters as initial guess\n",
    "        initial_params = [loc, 0, scale, shape]\n",
    "\n",
    "        # Negative Log-Likelihood Function\n",
    "        def negative_log_likelihood(params, x, t, g):\n",
    "            beta0, beta1, beta2, sigma, xi = params\n",
    "            mu = beta0 + beta1 * (t - 1951) + beta2 * g  # Location depends on years and GMT\n",
    "            if sigma <= 0:\n",
    "                return np.inf\n",
    "            return -np.sum(gev.logpdf(x, c=xi, loc=mu, scale=sigma))\n",
    "\n",
    "        # Optimization\n",
    "        initial_params = [loc, 0, 0, scale, shape]\n",
    "        result = minimize(negative_log_likelihood, initial_params, args=(annual_max_precip, years, gmt),\n",
    "                         method='SLSQP', bounds=[(-np.inf, np.inf), (-np.inf, np.inf), (-np.inf, np.inf), (0, np.inf), (-1, 1)])\n",
    "        beta0, beta1, beta2, sigma, xi = result.x\n",
    "\n",
    "        # Calculate non-stationary return levels\n",
    "        non_stationary_return_levels = {}\n",
    "        for rp in self.return_periods:\n",
    "            non_stationary_return_levels[rp] = gev.ppf(1 - 1/rp, c=xi, loc=beta0 + beta1 * (years - self.start_year) + beta2 * gmt, scale=sigma)\n",
    "        # Calculate return levels for each return period for last year\n",
    "        non_stationary_return_levels_end_year = {}\n",
    "        for rp in self.return_periods:\n",
    "            non_stationary_return_levels_end_year[rp] = gev.ppf(1 - 1/rp, c=xi, loc=beta0 + beta1 * (self.end_year - self.start_year) + beta2 * gmt_end, scale=sigma)\n",
    "        \n",
    "        # Check if catchment ID is present in the intersection DataFrame\n",
    "        filename = os.path.splitext(os.path.basename(self.excel_file_path))[0]\n",
    "        self.catchment_id = int(filename)\n",
    "        self.intersection_df['Catchment ID'] = self.intersection_df['Catchment ID'].astype(int)\n",
    "        filtered_df = self.intersection_df[self.intersection_df['Catchment ID'] == self.catchment_id]\n",
    "        if not filtered_df.empty:\n",
    "            self.Latitude = filtered_df['Latitude'].values[0]\n",
    "            self.Longitude = filtered_df['Longitude'].values[0]\n",
    "            self.resultsNon_Stationary_Stationary_Analysis_location_vary.append({\n",
    "            'Catchment ID': self.catchment_id,\n",
    "                'Latitude' : self.Latitude,\n",
    "                'Longitude' : self.Longitude,\n",
    "            'Stationary Location parameter': loc,\n",
    "            'Stationary Shape parameter': shape,\n",
    "            'Stationary Scale parameter': scale,\n",
    "            **{f'Stationary Return value for {rp}-year': stationary_return_levels[rp].item() if isinstance(stationary_return_levels[rp], np.ndarray) else stationary_return_levels[rp] for rp in self.return_periods},\n",
    "            'Location parameter(beta0)': beta0,\n",
    "            f'Location parameter(beta1*(years-{self.start_year}))': beta1,\n",
    "            f'Location parameter(beta2*(gmt))': beta2,\n",
    "            f'Location parameter for year {self.end_year}': beta0 + beta1 * (self.end_year - self.start_year) + beta2 * (gmt_end.item() if isinstance(gmt_end, np.ndarray) else gmt_end),\n",
    "            f'Shape parameter for year {self.end_year}': xi,\n",
    "            f'Scale parameter for year {self.end_year}': sigma,\n",
    "            **{f'Non-Stationary Return value for {rp}-year': non_stationary_return_levels_end_year[rp].item() if isinstance(non_stationary_return_levels_end_year[rp], np.ndarray) else non_stationary_return_levels_end_year[rp] for rp in self.return_periods},\n",
    "            **{f'Change in Precipitation for return period {rp}-year': (non_stationary_return_levels_end_year[rp] - stationary_return_levels[rp]).item() if isinstance((non_stationary_return_levels_end_year[rp] - stationary_return_levels[rp]), np.ndarray) else non_stationary_return_levels_end_year[rp] - stationary_return_levels[rp] for rp in self.return_periods}  \n",
    "            })\n",
    "        else:\n",
    "            self.Latitude = None\n",
    "            self.Longitude = None\n",
    "            print(f\"No matching catchment ID {self.catchment_id} found in the intersection DataFrame. Skipping.\")\n",
    "\n",
    "        print(self.catchment_id)\n",
    "        \n",
    "       \n",
    "#         print(f\"Non-Stationary GEV Parameters: beta0={beta0}, beta1={beta1}, beta2={beta2}, sigma={sigma}, xi={xi}\")\n",
    "       \n",
    "        # # Plot location parameter over the years\n",
    "        # non_stationary_locations = beta0 + beta1 * (years - 1951) + beta2 * gmt\n",
    "        # plt.figure(figsize=(10, 5))\n",
    "        # plt.plot(years, non_stationary_locations, label='Location Parameter')\n",
    "        # plt.xlabel('Year')\n",
    "        # plt.ylabel('Location Parameter')\n",
    "        # equation_text = f\"Location = {beta0:.2f} + {beta1:.2f} * (Year - 1951) + {beta2:.2f} * GMT\"\n",
    "        # plt.text(0.05, 0.95, equation_text, transform=plt.gca().transAxes, fontsize=12, verticalalignment='top')\n",
    "        # plt.legend()\n",
    "        # plt.title('Location Parameter Over Time')\n",
    "        # plt.show()\n",
    "       \n",
    "        # # Plot stationary and non-stationary return levels along with annual maximum precipitation\n",
    "        # plt.figure(figsize=(10, 5))\n",
    "        # for rp in self.return_periods:\n",
    "        #     plt.plot(years, non_stationary_return_levels[rp], label=f'Non-Stationary {rp}-Year Return Level')\n",
    "        # for rp in self.return_periods:\n",
    "        #     plt.axhline(y=stationary_return_levels[rp], color='r', linestyle='--', label=f'Stationary {rp}-Year Return Level' if rp == self.return_periods[0] else \"\")\n",
    "        # plt.plot(years, annual_max_precip, 'o-', label='Annual Maximum Precipitation', color='blue')\n",
    "        # plt.xlabel('Year')\n",
    "        # plt.ylabel('Return Level')\n",
    "        # plt.legend()\n",
    "        # plt.title('Comparison of Stationary and Non-Stationary Return Levels with Annual Maximum Precipitation')\n",
    "        # plt.show()\n",
    "       \n",
    "        # # Plot stationary and non-stationary return levels\n",
    "        # plt.figure(figsize=(10, 5))\n",
    "        # for rp in self.return_periods:\n",
    "        #     plt.plot(years, non_stationary_return_levels[rp], label=f'Non-Stationary {rp}-Year Return Level')\n",
    "        # for rp in self.return_periods:\n",
    "        #     plt.axhline(y=stationary_return_levels[rp], color='r', linestyle='--', label=f'Stationary {rp}-Year Return Level' if rp == self.return_periods[0] else \"\")\n",
    "        # plt.xlabel('Year')\n",
    "        # plt.ylabel('Return Level')\n",
    "        # plt.legend()\n",
    "        # plt.title('Comparison of Stationary and Non-Stationary Return Levels')\n",
    "        # plt.show()\n",
    "       \n",
    "        # # Calculate Goodness of Fit\n",
    "        # sample_quantiles = np.sort(annual_max_precip)\n",
    "        # modeled_quantiles = gev.ppf((np.arange(len(annual_max_precip)) + 1) / (len(annual_max_precip) + 1), c=xi, loc=beta0 + beta1 * (years - 1951) + beta2 * gmt, scale=sigma)\n",
    "        # plt.figure(figsize=(10, 5))\n",
    "        # plt.plot(sample_quantiles, modeled_quantiles, 'o')\n",
    "        # plt.plot([min(sample_quantiles), max(sample_quantiles)], [min(sample_quantiles), max(sample_quantiles)], 'r--')\n",
    "        # plt.xlabel('Sample Quantiles')\n",
    "        # plt.ylabel('Modeled Quantiles')\n",
    "        # plt.title('QQ Plot of Non-Stationary GEV Model')\n",
    "        # plt.show()\n",
    "       \n",
    "\n",
    "        # # Plot stationary GEV distribution\n",
    "        # x = np.linspace(min(annual_max_precip), max(annual_max_precip), 100)\n",
    "        # plt.plot(x, gev.pdf(x, c=shape, loc=loc, scale=scale), label='Stationary GEV', linestyle='-',color='black')\n",
    "\n",
    "        # # Plot non-stationary GEV distribution for year 2014\n",
    "        # mu_non_stationary = beta0 + beta1 * (2014 - 1951) + beta2 * gmt[-1]\n",
    "        # plt.plot(x, gev.pdf(x, c=xi, loc=mu_non_stationary, scale=sigma), label=f'Non-Stationary GEV (Year 2014)', linestyle='-', color='g')\n",
    "        # plt.xlabel('Precipitation (mm)')\n",
    "        # plt.ylabel('Probability Density')\n",
    "        # plt.title(f'GEV Distribution Comparison for {self.catchment_id}')\n",
    "        # plt.legend()\n",
    "        # plt.grid(True)\n",
    "        # plt.tight_layout()\n",
    "        # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c108d035-653c-4af1-9972-5c9252ceb7d9",
   "metadata": {},
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29b842b8-c7be-4464-af45-92d80baa0df8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_model(model_name, data_start_year, start_year, end_year, return_periods,duration):\n",
    "    # Set paths and parameters\n",
    "    Model_Folder_Path = f\"/DATA2/ALL_DATA_FOR_USERS/CMIP6_models_forcing/{model_name}\"\n",
    "    excel_file_path = r\"/DATA1/ankit_new_data/CatchmentAreaPointsArea10000\"\n",
    "    intersection_point_path = r\"/DATA1/ankit_new_data/Intersection Points After Preprocessing (Catchment area greater then 10000km2).xlsx\"\n",
    "    GMT_File_Path = f\"/DATA1/ankit_new_data/gmt_data/Global_Mean_Temperature/{model_name}_Global_mean_temp.txt\"\n",
    "\n",
    "    # Initialize a list to collect results from all catchments\n",
    "    all_results_location_vary = []\n",
    "    all_results_location_window_size = []\n",
    "\n",
    "    # Loop through each model folder in Model_Folder_Path\n",
    "    model_folders = [f for f in os.listdir(Model_Folder_Path) if os.path.isdir(os.path.join(Model_Folder_Path, f))]\n",
    "    for model_folder in model_folders:\n",
    "        folder_path = os.path.join(Model_Folder_Path, model_folder)\n",
    "        scenario = model_folder.split('_')[1]\n",
    "        # print(scenario)\n",
    "        # Loop through all Excel files in the excel_file_path\n",
    "        excel_files = [file for file in os.listdir(excel_file_path) if file.endswith(\".xlsx\")]\n",
    "        for i, excel_file in enumerate(excel_files):\n",
    "            excel_path = os.path.join(excel_file_path, excel_file)\n",
    "            analyzer = AnnualMaxPrecipitationAnalyzer(\n",
    "                folder_path=folder_path, \n",
    "                excel_file_path=excel_path, \n",
    "                intersection_point_path =intersection_point_path, \n",
    "                GMT_File_Path=GMT_File_Path, \n",
    "                data_start_year=data_start_year, \n",
    "                start_year=start_year, \n",
    "                end_year=end_year, \n",
    "                return_periods=return_periods\n",
    "            )\n",
    "            analyzer.process_files(duration=duration)\n",
    "            # analyzer.Non_Stationary_Stationary_Analysis_Using_Window_Size(window_size=25)\n",
    "            analyzer.Non_Stationary_Stationary_Analysis_location_vary(scenario)\n",
    "            # Extend the all_results list with the results from the current analyzer\n",
    "            all_results_location_vary.extend(analyzer.resultsNon_Stationary_Stationary_Analysis_location_vary)\n",
    "            print(f\"Processed {i+1} catchments in folder {model_folder}\")\n",
    "        # window size\n",
    "        # results_df_location_window_size = pd.DataFrame(all_results_location_window_size)\n",
    "        # output_excel_path_splitwise = os.path.join(r\"/DATA1/ankit_new_data\", f\"{model_folder}_windowsize.xlsx\")\n",
    "        # results_df_location_window_size.to_excel(output_excel_path_splitwise, index=False)\n",
    "        # all_results_location_window_size.clear()\n",
    "        # locationvary\n",
    "        # Save the results to an Excel file named after the model folder\n",
    "        results_df_location_vary = pd.DataFrame(all_results_location_vary)\n",
    "        output_excel_path_locationvary = os.path.join(r\"/DATA1/ankit_new_data/Different Model Analysis\", f\"{model_name}_{scenario}_Anlaysis_{start_year}-{end_year}_locationvary.xlsx\")\n",
    "        results_df_location_vary.to_excel(output_excel_path_locationvary, index=False)\n",
    "        all_results_location_vary.clear()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a596bdd8-f78a-4269-82b6-5bee54420cb5",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model_name = \"IPSL-CM6A-LR\"  # Replace this with any model name you want to process\n",
    "    data_start_year = 1850\n",
    "    start_year = 2071\n",
    "    end_year = 2100\n",
    "    return_periods = [25, 50, 100]\n",
    "    duration = 1\n",
    "    process_model(model_name, data_start_year, start_year, end_year, return_periods,duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1fb767-cbbb-45ee-9cc5-c50e598b35a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "# Directory path where the files are located\n",
    "GMT_File_Path = \"/DATA1/ankit_new_data/gmt_data/Global_Mean_Temperature\"\n",
    "# Function to extract model names from file names\n",
    "def extract_model_name(filename):\n",
    "    return filename.split('_')[0]  # Assuming model name is before '_Global_mean_temp.txt'\n",
    "files = os.listdir(GMT_File_Path)\n",
    "unique_models = set()\n",
    "for file in files:\n",
    "    if file.endswith('_Global_mean_temp.txt'):\n",
    "        model_name = extract_model_name(file)\n",
    "        unique_models.add(model_name)\n",
    "\n",
    "\n",
    "# Function to be executed in parallel for each model\n",
    "def process_model_wrapper(model_name):\n",
    "    data_start_year = 1850\n",
    "    start_year = 2071\n",
    "    end_year = 2100\n",
    "    return_periods = [25, 50, 100]\n",
    "    duration = 1\n",
    "    process_model(model_name, data_start_year, start_year, end_year, return_periods, duration)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with multiprocessing.Pool() as pool:\n",
    "        pool.map(process_model_wrapper, unique_models)\n",
    "    print(\"All models processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99af3236-4112-4033-9bda-51585835dd45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
